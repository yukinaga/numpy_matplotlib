{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHGJwZfE2r0G+l2fJuDO4Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/numpy_matplotlib/blob/main/section_4/03_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmbZSCKoMwWZ"
      },
      "source": [
        "# NumPyによるニューラルネットワーク\n",
        "NumPyを使い「ニューラルネットワーク」を実装します。  \n",
        "ニューラルネットワークは、「バックプロパゲーション」により学習することができます。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhxGBS5DMwWd"
      },
      "source": [
        "## ●ニューラルネットワークの実装\n",
        "2次元の座標が、sin関数の曲線より上に位置するか、下に位置するのかを判定するニューラルネットワークを実装します。  \n",
        "NumPyを使って実装し、maplotlibで結果を可視化します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_bzBw8WMwWe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -- 座標 --\n",
        "X = np.arange(-1.0, 1.1, 0.1)\n",
        "Y = np.arange(-1.0, 1.1, 0.1)\n",
        "\n",
        "# -- 入力、正解データを作成 --\n",
        "input_data = []\n",
        "correct_data = []\n",
        "for x in X:\n",
        "    for y in Y:\n",
        "        input_data.append([x, y])\n",
        "        if y < np.sin(np.pi * x):  # y座標がsinカーブよりも下であれば\n",
        "            correct_data.append([0, 1])  # 下の領域\n",
        "        else:\n",
        "            correct_data.append([1, 0])  # 上の領域\n",
        "            \n",
        "n_data = len(correct_data)  # データ数\n",
        "\n",
        "input_data = np.array(input_data)\n",
        "correct_data = np.array(correct_data)\n",
        "            \n",
        "# -- 各設定値 --\n",
        "n_in = 2  # 入力層のニューロン数\n",
        "n_mid = 6  # 中間層のニューロン数\n",
        "n_out = 2  # 出力層のニューロン数\n",
        "\n",
        "wb_width = 0.01  # 重みとバイアスの広がり具合\n",
        "eta = 0.1  # 学習係数\n",
        "epoch = 51\n",
        "interval = 2  # 経過の表示間隔\n",
        "\n",
        "# -- 中間層 --\n",
        "class MiddleLayer:\n",
        "    def __init__(self, n_upper, n):\n",
        "        self.w = wb_width * np.random.randn(n_upper, n)  # 重み（行列）\n",
        "        self.b = wb_width * np.random.randn(n)  # バイアス（ベクトル）\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        u = np.dot(x, self.w) + self.b\n",
        "        self.y = 1/(1+np.exp(-u))  # シグモイド関数\n",
        "    \n",
        "    def backward(self, grad_y):\n",
        "        delta = grad_y * (1-self.y)*self.y\n",
        "        \n",
        "        self.grad_w = np.dot(self.x.T, delta)\n",
        "        self.grad_b = np.sum(delta, axis=0)\n",
        "        \n",
        "        self.grad_x = np.dot(delta, self.w.T) \n",
        "        \n",
        "    def update(self, eta):\n",
        "        self.w -= eta * self.grad_w\n",
        "        self.b -= eta * self.grad_b\n",
        "\n",
        "# -- 出力層 --\n",
        "class OutputLayer:\n",
        "    def __init__(self, n_upper, n):\n",
        "        self.w = wb_width * np.random.randn(n_upper, n)  # 重み（行列）\n",
        "        self.b = wb_width * np.random.randn(n)  # バイアス（ベクトル）\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        u = np.dot(x, self.w) + self.b\n",
        "        self.y = np.exp(u)/np.sum(np.exp(u), axis=1, keepdims=True)  # ソフトマックス関数\n",
        "    \n",
        "    def backward(self, t):\n",
        "        delta = self.y - t\n",
        "        \n",
        "        self.grad_w = np.dot(self.x.T, delta)\n",
        "        self.grad_b = np.sum(delta, axis=0)\n",
        "        \n",
        "        self.grad_x = np.dot(delta, self.w.T) \n",
        "\n",
        "    def update(self, eta):\n",
        "        self.w -= eta * self.grad_w\n",
        "        self.b -= eta * self.grad_b\n",
        "        \n",
        "# -- 各層の初期化 --\n",
        "middle_layer = MiddleLayer(n_in, n_mid)\n",
        "output_layer = OutputLayer(n_mid, n_out)\n",
        "\n",
        "# -- 学習 --\n",
        "sin_data = np.sin(np.pi * X) # 結果の検証用\n",
        "for i in range(epoch):\n",
        "\n",
        "    # インデックスをシャッフル\n",
        "    index_random = np.arange(n_data)\n",
        "    np.random.shuffle(index_random)\n",
        "    \n",
        "    # 結果の表示用\n",
        "    total_error = 0\n",
        "    x_1 = []\n",
        "    y_1 = []\n",
        "    x_2 = []\n",
        "    y_2 = []\n",
        "       \n",
        "    for idx in index_random:\n",
        "        \n",
        "        x = input_data[idx]\n",
        "        t = correct_data[idx]\n",
        "\n",
        "        # 順伝播\n",
        "        middle_layer.forward(x.reshape(1,2))\n",
        "        output_layer.forward(middle_layer.y)\n",
        "\n",
        "        # 逆伝播\n",
        "        output_layer.backward(t.reshape(1,2))\n",
        "        middle_layer.backward(output_layer.grad_x)\n",
        "        \n",
        "        # 重みとバイアスの更新\n",
        "        middle_layer.update(eta)\n",
        "        output_layer.update(eta)\n",
        "        \n",
        "        if i%interval == 0:\n",
        "            \n",
        "            y = output_layer.y.reshape(-1)  # 行列をベクトルに戻す\n",
        "            \n",
        "            # 誤差の計算\n",
        "            total_error += - np.sum(t * np.log(y + 1e-7)) # 交差エントロピー誤差\n",
        "            \n",
        "            # 確率の大小を比較し、分類する\n",
        "            if y[0] > y[1]:\n",
        "                x_1.append(x[0])\n",
        "                y_1.append(x[1])\n",
        "            else:\n",
        "                x_2.append(x[0])\n",
        "                y_2.append(x[1])\n",
        "            \n",
        "    if i%interval == 0:\n",
        "        \n",
        "        # 出力のグラフ表示\n",
        "        plt.plot(X, sin_data, linestyle=\"dashed\")\n",
        "        plt.scatter(x_1, y_1, marker=\"+\")\n",
        "        plt.scatter(x_2, y_2, marker=\"x\")\n",
        "        plt.show()\n",
        "        \n",
        "        # エポック数と誤差の表示\n",
        "        print(\"Epoch:\" + str(i) + \"/\" + str(epoch), \"Error:\" + str(total_error/n_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxFgknB8MwWg"
      },
      "source": [
        "学習が進むにつれて、sinカーブの上下に各座標を正しく分類できるようになっていく様子を確認できます。  "
      ]
    }
  ]
}